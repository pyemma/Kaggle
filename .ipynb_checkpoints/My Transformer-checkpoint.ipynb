{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1595b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f19392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        N: batch size\n",
    "        seq_len: sequience lenght (e.g. sentence length)\n",
    "        h: number of heads\n",
    "        D_k: dim of key/query\n",
    "        D_v: dim of value\n",
    "        \n",
    "        This is the case of single head\n",
    "            query: N x seq_len x D_k\n",
    "            key: N x seq_len x D_k\n",
    "            value: N x seq_len x D_v\n",
    "        \n",
    "        In the case of multi head, the input would be\n",
    "            query: N x h x seq_len x D_k\n",
    "            key: N x h x seq_len x D_k\n",
    "            value: N x h x seq_len x D_v\n",
    "        \n",
    "        So to make it easily support the above case, we just need to make sure\n",
    "        that we we are working on the final 2 dim for matrix multi when we do\n",
    "        the key x query\n",
    "            \n",
    "        \"\"\"\n",
    "        d_k = query.shape[-1]\n",
    "        \n",
    "        dot_product = torch.matmul(query, torch.transpose(key, -2, -1)) / math.sqrt(d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            dot_product = dot_product.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        return torch.matmul(F.softmax(dot_product, dim=-1), value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8622b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, d_model, d_k, d_v, h=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.h = h\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        \n",
    "        # some invariant to check, in the future, d_k, d_v does not need to be provided\n",
    "        assert d_v == d_k\n",
    "        assert d_model // h == d_k\n",
    "        \n",
    "        self.WQ = nn.Linear(d_model, d_model)\n",
    "        self.WK = nn.Linear(d_model, d_model)\n",
    "        self.WV = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.attn = Attention()\n",
    "        \n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "            query: N x seq_len x D_model\n",
    "            key: N x seq_len x D_model\n",
    "            value: N x seq_len x D_model\n",
    "        \"\"\"\n",
    "        \n",
    "        N, seq = query.shape[0], query.shape[1]\n",
    "        \n",
    "        q = self.WQ(query)  # N x seq_len x d_model\n",
    "        k = self.WK(key)  # N x seq_len x d_model\n",
    "        v = self.WV(value)  # N x seq_len x d_model\n",
    "        \n",
    "        q = q.view(N, -1, self.h, self.d_k).transpose(1, 2)  # N x h x seq x d_k\n",
    "        k = k.view(N, -1, self.h, self.d_k).transpose(1, 2)  # N x h x seq x d_k\n",
    "        v = v.view(N, -1, self.h, self.d_v).transpose(1, 2)  # N x h x seq x d_v\n",
    "        \n",
    "        \n",
    "        \n",
    "        out = self.attn(q, k, v)  # N x h x seq x d_v\n",
    "        out = out.transpose(1, 2)  # N x seq x h x d_v\n",
    "        \n",
    "        return self.fc(out.reshape(N, seq, -1))  # N x seq x D_model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a43e6f08",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m5/83hxq45d10bb_n93lz2607qc0000gn/T/ipykernel_69909/3115852983.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/m5/83hxq45d10bb_n93lz2607qc0000gn/T/ipykernel_69909/3462405820.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# N x seq x h x d_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# N x seq x D_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "d_model = 10\n",
    "seq_len = 10\n",
    "\n",
    "d_k, d_v = 5, 5\n",
    "\n",
    "query = torch.rand(N, seq_len, d_model)\n",
    "key = torch.rand(N, seq_len, d_model)\n",
    "value = torch.rand(N, seq_len, d_model)\n",
    "\n",
    "# WQ = nn.Linear(3, d_model, d_k)\n",
    "# WQ(query)\n",
    "\n",
    "mh = MultiHead(d_model, d_k, d_v, h=2)\n",
    "mh(query, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WQ = nn.Linear(3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6e7b61de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, d_model, d_k, d_v, num_heads=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.h = num_heads\n",
    "        \n",
    "        self.attns = nn.ModuleList()\n",
    "        self.WQ = nn.ModuleList()\n",
    "        self.WK = nn.ModuleList()\n",
    "        self.WV = nn.ModuleList()\n",
    "        \n",
    "        for _ in range(self.h):\n",
    "            self.attns.append(Attention())\n",
    "            self.WQ.append(nn.Linear(d_model, d_k))\n",
    "            self.WK.append(nn.Linear(d_model, d_k))\n",
    "            self.WV.append(nn.Linear(d_model, d_v))\n",
    "        \n",
    "        self.fc = nn.Linear(num_heads * d_v, d_model)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \n",
    "        heads_out = []\n",
    "        for i in range(self.h):\n",
    "            heads_out.append(self.attns[i](self.WQ[i](query), self.WK[i](query), self.WV[i](value), mask=mask))\n",
    "        \n",
    "        return self.fc(\n",
    "            torch.concat(tuple(heads_out), dim=-1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f49788fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddAndNorm(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, out1, out2):\n",
    "        return self.layer_norm(out1 + out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "301ec2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, 4 * d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(4 * d_model, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3a44c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    return torch.from_numpy(\n",
    "        np.triu(np.ones((size, size)), k=1).astype('uint8')\n",
    "    ) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "25c55b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_k, d_v, num_heads=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.multi_head = MultiHead(d_model, d_k, d_v, num_heads=num_heads)\n",
    "        self.add_norm1 = AddAndNorm(d_model)\n",
    "        self.ffn = FFN(d_model)\n",
    "        self.add_norm2 = AddAndNorm(d_model)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "            x: N x seq_len x d_model\n",
    "            mask: seq_len x seq_len, in encoder, we need this to prevent padding\n",
    "        \"\"\"\n",
    "        out1 = self.add_norm1(x, self.multi_head(x, x, x, mask=mask))\n",
    "        out2 = self.add_norm2(out1, self.ffn(out1))\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ed519130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_k, d_v, num_heads=2):\n",
    "        super().__init__()\n",
    "        self.masked_multi_head = MultiHead(d_model, d_k, d_v, num_heads=num_heads)\n",
    "        self.add_norm1 = AddAndNorm(d_model)\n",
    "        self.multi_head = MultiHead(d_model, d_k, d_v, num_heads=num_heads)\n",
    "        self.add_norm2 = AddAndNorm(d_model)\n",
    "        self.ffn = FFN(d_model)\n",
    "        self.add_norm3 = AddAndNorm(d_model)\n",
    "    \n",
    "    def forward(self, x, encoder_out, mask=None):\n",
    "        \"\"\"\n",
    "            x: N x seq_len x d_model\n",
    "            encoder_out: N x seq_len x d_model\n",
    "            mask: seq_len x seq_len\n",
    "        \"\"\"\n",
    "        out1 = self.add_norm1(\n",
    "            x, self.masked_multi_head(x, x, x, mask=mask)\n",
    "        )\n",
    "        out2 = self.add_norm2(\n",
    "            out1, self.multi_head(out1, encoder_out, encoder_out, mask=mask)\n",
    "        )\n",
    "        out3 = self.add_norm3(\n",
    "            out2, self.ffn(out2)\n",
    "        )\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3dd926c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, d_k, d_v, out_dim, num_heads=2):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderLayer(d_model, d_k, d_v, num_heads=num_heads)\n",
    "        self.decoder = DecoderLayer(d_model, d_k, d_v, num_heads=num_heads)\n",
    "        \n",
    "        self.fc = nn.Linear(d_model, out_dim)\n",
    "    \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        encoder_out = self.encoder(src, src_mask)\n",
    "        decoder_out = self.decoder(tgt, encoder_out, tgt_mask)\n",
    "        return F.softmax(self.fc(decoder_out), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9977fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super().__init__()\n",
    "        \n",
    "        pe = torch.ones((max_len, d_model)) \n",
    "        \n",
    "        pos = torch.arange(0, max_len).reshape((max_len, 1))\n",
    "        rng = torch.arange(0, d_model/2)\n",
    "        rng = 2*rng / d_model\n",
    "        div = torch.pow(10000, rng)\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(pos / div)\n",
    "        pe[:, 1::2] = torch.cos(pos / div)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            x: N x seq_len x d_model\n",
    "        \"\"\"\n",
    "        return x + self.pe[:x.shape[1], :].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "597cb686",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(voc_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.emb(x) / math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8817fa",
   "metadata": {},
   "source": [
    "Below is the function related to data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e852a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec41f75b",
   "metadata": {},
   "source": [
    "Below is the sections of playground for testing of the module above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc3559f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 10\n",
    "seq_len = 10\n",
    "\n",
    "d_k, d_v = 5, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9e019a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 5, d_model)\n",
    "label = torch.tensor([0.0, 1.0, 1.0, 0.0, 0.0]).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "72653b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7941,  1.8423,  0.2766,  1.8735,  0.6056,  1.4991,  0.1369,\n",
       "           1.0558,  0.1053,  1.1077],\n",
       "         [ 1.8124,  0.6735,  0.2615,  1.1507,  0.8948,  1.0303,  0.3383,\n",
       "           1.5239,  0.5827,  1.2680],\n",
       "         [ 1.4656,  0.3187,  1.2982,  1.1240,  0.2975,  1.9091,  0.9909,\n",
       "           1.1799,  0.5763,  1.1359],\n",
       "         [ 0.1657, -0.8468,  1.0620,  1.0904,  0.8925,  1.0388,  0.6975,\n",
       "           1.8768,  0.1383,  1.7975],\n",
       "         [-0.0167, -0.1900,  0.6836,  1.7922,  0.2277,  1.7875,  0.3755,\n",
       "           1.7339,  0.3565,  1.6054]]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = PositionalEncoding(d_model, 1000)\n",
    "x = torch.rand(1, 5, d_model)\n",
    "pe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "02e318a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pyemma/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(encoder.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "pred = encoder(x)\n",
    "loss = criterion(pred, label)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "93f6e46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0470, 0.1035, 0.0756, 0.0151, 0.1349, 0.0103, 0.0362, 0.0578,\n",
       "          0.0216, 0.1197, 0.0391, 0.0269, 0.0297, 0.0168, 0.0492, 0.0813,\n",
       "          0.0374, 0.0171, 0.0220, 0.0589],\n",
       "         [0.0228, 0.1159, 0.1013, 0.0301, 0.1040, 0.0168, 0.0687, 0.0217,\n",
       "          0.0092, 0.0952, 0.0347, 0.0192, 0.0108, 0.0518, 0.1153, 0.0695,\n",
       "          0.0241, 0.0187, 0.0231, 0.0470],\n",
       "         [0.0498, 0.0562, 0.0134, 0.0172, 0.1349, 0.0250, 0.0134, 0.0504,\n",
       "          0.0358, 0.0600, 0.0479, 0.0420, 0.0205, 0.1018, 0.0686, 0.0483,\n",
       "          0.0659, 0.0143, 0.0210, 0.1136],\n",
       "         [0.0408, 0.0766, 0.0582, 0.0123, 0.0890, 0.0110, 0.0442, 0.1523,\n",
       "          0.0359, 0.1230, 0.0312, 0.0355, 0.0707, 0.0200, 0.0221, 0.0517,\n",
       "          0.0258, 0.0195, 0.0220, 0.0583],\n",
       "         [0.0191, 0.0756, 0.0329, 0.0282, 0.0898, 0.0279, 0.0453, 0.0530,\n",
       "          0.0208, 0.0604, 0.0308, 0.0365, 0.0275, 0.1241, 0.1149, 0.0511,\n",
       "          0.0391, 0.0152, 0.0376, 0.0702]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = Transformer(d_model, d_k, d_v, out_dim=20)\n",
    "src = torch.rand(1, 5, d_model)\n",
    "tgt = torch.rand(1, 5, d_model)\n",
    "trans(src, tgt, src_mask=None, tgt_mask=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
